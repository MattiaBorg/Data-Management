{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page starting at 37775...\n",
      "Scraping page starting at 37800...\n",
      "Scraping page starting at 37825...\n",
      "Scraping page starting at 37850...\n",
      "Scraping page starting at 37875...\n",
      "Scraping page starting at 37900...\n",
      "Scraping page starting at 37925...\n",
      "Scraping page starting at 37950...\n",
      "Scraping page starting at 37975...\n",
      "Scraping page starting at 38000...\n",
      "Scraping page starting at 38025...\n",
      "Scraping page starting at 38050...\n",
      "Scraping page starting at 38075...\n",
      "Scraping page starting at 38100...\n",
      "Scraping page starting at 38125...\n",
      "Scraping page starting at 38150...\n",
      "Scraping page starting at 38175...\n",
      "Scraping page starting at 38200...\n",
      "Scraping page starting at 38225...\n",
      "Scraping page starting at 38250...\n",
      "Scraping page starting at 38275...\n",
      "Scraping page starting at 38300...\n",
      "Scraping page starting at 38325...\n",
      "Scraping page starting at 38350...\n",
      "Scraping page starting at 38375...\n",
      "Scraping page starting at 38400...\n",
      "Scraping page starting at 38425...\n",
      "Scraping page starting at 38450...\n",
      "Scraping page starting at 38475...\n",
      "Scraping page starting at 38500...\n",
      "Scraping page starting at 38525...\n",
      "Scraping page starting at 38550...\n",
      "Scraping page starting at 38575...\n",
      "Scraping page starting at 38600...\n",
      "Scraping page starting at 38625...\n",
      "Scraping page starting at 38650...\n",
      "Scraping page starting at 38675...\n",
      "Scraping page starting at 38700...\n",
      "Scraping page starting at 38725...\n",
      "Scraping page starting at 38750...\n",
      "Scraping page starting at 38775...\n",
      "Scraping page starting at 38800...\n",
      "Scraping page starting at 38825...\n",
      "Scraping page starting at 38850...\n",
      "Scraping page starting at 38875...\n",
      "Scraping page starting at 38900...\n",
      "Scraping page starting at 38925...\n",
      "Scraping page starting at 38950...\n",
      "Scraping page starting at 38975...\n",
      "Scraping page starting at 39000...\n",
      "Scraping page starting at 39025...\n",
      "Scraping page starting at 39050...\n",
      "Scraping page starting at 39075...\n",
      "Scraping page starting at 39100...\n",
      "Scraping page starting at 39125...\n",
      "Scraping page starting at 39150...\n",
      "Scraping page starting at 39175...\n",
      "Scraping page starting at 39200...\n",
      "Scraping page starting at 39225...\n",
      "Scraping page starting at 39250...\n",
      "Scraping page starting at 39275...\n",
      "Scraping page starting at 39300...\n",
      "Scraping page starting at 39325...\n",
      "Scraping page starting at 39350...\n",
      "Scraping page starting at 39375...\n",
      "Scraping page starting at 39400...\n",
      "Scraping page starting at 39425...\n",
      "Scraping page starting at 39450...\n",
      "Scraping page starting at 39475...\n",
      "Scraping page starting at 39500...\n",
      "Scraping page starting at 39525...\n",
      "Scraping page starting at 39550...\n",
      "Scraping page starting at 39575...\n",
      "Scraping page starting at 39600...\n",
      "Scraping page starting at 39625...\n",
      "Scraping page starting at 39650...\n",
      "Scraping page starting at 39675...\n",
      "Scraping page starting at 39700...\n",
      "Scraping page starting at 39725...\n",
      "Scraping page starting at 39750...\n",
      "Scraping page starting at 39775...\n",
      "Scraping page starting at 39800...\n",
      "Scraping page starting at 39825...\n",
      "Data scraping complete. Saved to basketball_transactions.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL for scraping\n",
    "BASE_URL = \"https://www.prosportstransactions.com/basketball/Search/SearchResults.php\"\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(start):\n",
    "    params = {\n",
    "        'Player': '',\n",
    "        'Team': '',\n",
    "        'BeginDate': '',\n",
    "        'EndDate': '',\n",
    "        'ILChkBx': 'yes',\n",
    "        'Submit': 'Search',\n",
    "        'start': start\n",
    "    }\n",
    "    \n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'datatable'})\n",
    "    \n",
    "    if not table:\n",
    "        print(f\"No table found on page starting at {start}\")\n",
    "        return []\n",
    "\n",
    "    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cols = [col.text.strip() for col in row.find_all('td')]\n",
    "        data.append(cols)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Main scraping logic\n",
    "def scrape_last_season_pages():\n",
    "    all_data = []\n",
    "    \n",
    "    for page in range(1512, 1594 + 1):  # Iterate through pages 1512 to 1612\n",
    "        start = (page - 1) * 25  # Calculate the correct \"start\" parameter\n",
    "        print(f\"Scraping page starting at {start}...\")\n",
    "        page_data = scrape_page(start)\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    columns = [\"Date\", \"Team\", \"Acquired\", \"Relinquished\", \"Notes\"]\n",
    "    df = pd.DataFrame(all_data, columns=columns)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(\"basketball_transactions.csv\", index=False)\n",
    "    print(\"Data scraping complete. Saved to basketball_transactions.csv.\")\n",
    "\n",
    "# Execute the scraping function\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_last_season_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba01fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
